{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN1CZxFm/ljJ4Glig0xbmAX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LivingstonTardzenyuy/Deep-Learning-with-TensorFlow/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone project 2: SkimLit.\n",
        "\n",
        "The purpose of this notebook is to build an NLP model to make reading medical abstract easier.\n",
        "\n",
        "The paper we're replicating(the source of the dataset) is available here: https://arxiv.org/abs/1710.06071 .\n",
        "\n"
      ],
      "metadata": {
        "id": "4_StgL083RjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm access to a GPU.\n",
        "\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCzO6al84Aay",
        "outputId": "ad5bf309-da54-4c03-d0cf-15091203ae3a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-4c324027-0c61-de9d-61dd-ccc00c2efdd1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data.\n",
        "\n",
        "Since we'll be replicating the paper above (PubMed 200k RCT), let's download the dataset used.\n",
        "\n",
        "We can do so from the authors github. https://github.com/Franck-Dernoncourt/pubmed-rct"
      ],
      "metadata": {
        "id": "PAWesjth4XsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the github dataset\n",
        "\n",
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYbBZyra5Brq",
        "outputId": "22358068-e5a8-432d-9412-46656580739c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 39 (delta 8), reused 5 (delta 5), pack-reused 25 (from 1)\u001b[K\n",
            "Receiving objects: 100% (39/39), 177.08 MiB | 39.83 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Updating files: 100% (13/13), done.\n",
            "PubMed_200k_RCT\t\t\t\t       PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign  README.md\n",
            "PubMed_20k_RCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what files are in the PubMed 20k datasets.\n",
        "\n",
        "!ls pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX9A7Hw45El1",
        "outputId": "647ee6d2-6be4-4ed2-d24d-fc9d8a5a23b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start our experiments using the 20k dataset with numbers replaced by \"@\" sign.\n",
        "\n",
        "data_dir = \"/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "2F6wn7xc5tPh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check all of the file names in the target directory.\n",
        "import os\n",
        "\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nNYP_y-76Iw",
        "outputId": "3c4d953c-97f1-4a1f-f8bd-af2b1511b8c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess data.\n",
        "\n",
        "Now we've got some text data, it's time to become one with it.\n",
        "\n",
        "One of the best ways to become one with the data is to *Visualize Visualize Visualize*\n",
        "\n",
        "So with that in mind, let's write a function to read in all of the lines of a target text file."
      ],
      "metadata": {
        "id": "d2Xxp1AG8GfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Create function to read line from doc.\n",
        "\n",
        " def get_lines(filename):\n",
        "  \"\"\"\n",
        "    Read a file name and return a list of lines as a list.\n",
        "  \"\"\"\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "id": "7AEU1Nue83sU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lines = get_lines(data_dir + \"train.txt\")\n",
        "train_lines[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr5yf4ay9qnp",
        "outputId": "2a61d3f1-95fb-453a-8b5c-61120855517f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcvUxARh9tnR",
        "outputId": "0d4dfaf9-f4d4-4001-a93e-6cc28a30a12c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210040"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's think about how we want our data to look.\n",
        "\n",
        "Let's think about how we want our data to look.\n",
        "\n",
        "one possible way is to turn our words into a list of dic.\n",
        "\n",
        "'''\n",
        "[{'line_number': 0,\n",
        "    'target': 'BACKGROUND ',\n",
        "    'text': 'Emotional eating is associated with overeating and the development of obesity .\\n'\n",
        "    total_lines': 11\n",
        "}]\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "aGG8Xvnw-5hC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"\n",
        "    Returns a list of dictionaries of abstract line data.\n",
        "\n",
        "    Takes in filename, read it contents and sorts through each line,\n",
        "    extracting things like the target label, text of the sentence,\n",
        "    how many sentences are in current abstract and what sentence number the target line is.\n",
        "\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename)   # get all lines from filename\n",
        "  abstract_lines = \"\"                 # empty list to hold lines\n",
        "  abstract_samples = []               # create an empty list of abstracts.\n",
        "\n",
        "  # Loop through each line in the target file.\n",
        "  for line in input_lines:\n",
        "\n",
        "    if line.startswith(\"###\"):\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\"   # reset the abstract string if the line is an 1D line.\n",
        "    elif line.isspace():\n",
        "      abstract_line_split = abstract_lines.split(\"\\n\")      # split abstract into seperate lines.\n",
        "\n",
        "      # iteract through each line in a single abstract.\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data  = {}\n",
        "        target_text_split = abstract_line.split(\"\\t\")\n",
        "        line_data['target'] = target_text_split[0]  # get target label.\n",
        "        line_data['text'] = target_text_split[1].lower()   # get target text and lower it.\n",
        "        line_data['line_number'] = abstract_line_number\n",
        "        line_data['total_lines'] = len(abstract_line_split) -1 # -1 means we start counting from 0.\n",
        "        abstract_samples.append(line_data)\n",
        "\n",
        "    else:  # if above conditions not meet. the lines contains are labelled sentences\n",
        "      abstract_lines += line\n",
        "  return abstract_samples\n"
      ],
      "metadata": {
        "id": "NKtelMg1_XzU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\")  # dev is another name for validation.\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "\n",
        "len(train_samples), len(val_samples), len(test_samples)"
      ],
      "metadata": {
        "id": "42o_OOJ9clLi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "5ce3d2ae-d5a3-4385-b23b-bdd631d7a942"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c096be642673>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_text_with_line_numbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"train.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_text_with_line_numbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"dev.txt\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# dev is another name for validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_text_with_line_numbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"test.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-411289a8cd26>\u001b[0m in \u001b[0;36mpreprocess_text_with_line_numbers\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtarget_text_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabstract_line\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mline_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_text_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# get target label.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mline_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_text_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# get target text and lower it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mline_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'line_number'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabstract_line_number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mline_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_lines'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstract_line_split\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m# -1 means we start counting from 0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0EaOUCuLtQsv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}