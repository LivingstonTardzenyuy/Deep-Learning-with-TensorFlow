{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LivingstonTardzenyuy/Deep-Learning-with-TensorFlow/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLmfm88uKJhU"
      },
      "source": [
        " # Introduction to NLP Fundamentals in TensorFlow.\n",
        "\n",
        " NLP has the goal of deriving information out of natural language (could be sequence of text or words).\n",
        " Another common term for NLP problems is sequence to sequence problems (seq2seq)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_naAdvGUm0H",
        "outputId": "1b647c9f-4a23-469b-cd10-4dd3214be093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Mar  8 04:45:08 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU.\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6ZEFgvSUxZb",
        "outputId": "e6b4f0b9-66f9-40c8-985e-cdda6f173485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-08 04:45:08--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-08 04:45:08 (106 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Get helper functions.\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1P4lXnbl_HH"
      },
      "source": [
        "## Get our text dataset.\n",
        "\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP dataset(text samples of Tweets labelled as diaster or not diaster).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLh17qfIsqp-",
        "outputId": "a42b35da-c888-446e-f87a-983d802bc7a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-08 04:45:12--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.200.207, 74.125.130.207, 74.125.68.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.200.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K   719KB/s    in 0.8s    \n",
            "\n",
            "2025-03-08 04:45:13 (719 KB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# unzip data.\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PQibi8KgsydE",
        "outputId": "5c8ba29d-649b-400e-d72f-085221b95851"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9edcd17f-3990-492d-b0c6-d0fc1ff6b86d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9edcd17f-3990-492d-b0c6-d0fc1ff6b86d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9edcd17f-3990-492d-b0c6-d0fc1ff6b86d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9edcd17f-3990-492d-b0c6-d0fc1ff6b86d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4e2c3b67-9994-4773-89fe-4e800f7bdf11\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e2c3b67-9994-4773-89fe-4e800f7bdf11')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4e2c3b67-9994-4773-89fe-4e800f7bdf11 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 7613,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3137,\n        \"min\": 1,\n        \"max\": 10873,\n        \"num_unique_values\": 7613,\n        \"samples\": [\n          3796,\n          3185,\n          7769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"injury\",\n          \"nuclear%20reactor\",\n          \"engulfed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3341,\n        \"samples\": [\n          \"Oklahoma\",\n          \"Starling City\",\n          \"Trinidad and Tobago\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7503,\n        \"samples\": [\n          \"Three Homes Demolished in Unrecognized Arab Village - International Middle East Media Center http://t.co/ik8m4Yi9T4\",\n          \"Reid Lake fire prompts campground evacuation order http://t.co/jBODKM6rBU\",\n          \"FAAN orders evacuation of abandoned aircraft at MMA http://t.co/dEvYbnVXGQ via @todayng\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Reading the file with pandas.\n",
        "import pandas as pd\n",
        "\n",
        "train_df  = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets' shuffle our dataFrame.\n",
        "train_df_shuffled = train_df.sample(\n",
        "    frac=1,   # Frac is what percentage of the data to shuffle, 1 is equal to 100\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "W4jZeo4MEh32"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What are the totoal number of samples.\n",
        "\n",
        "len(train_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3wMatRiFq5X",
        "outputId": "d9b5586e-ebe0-4e91-9140-1abc580bc548"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some random sample examples.\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5)    # create random indexes not higher than the totla number of samples.\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln4SvCLAF0mv",
        "outputId": "858e324c-c17b-41cb-eb84-0d55beb82225"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@chaosmagician97 awesome!! I saw he was bleeding pretty bad\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Wreckage 'Conclusively Confirmed' as From MH370: Malaysia PM: Investigators and the families of those who were... http://t.co/4sf0rgn8Wo\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Best movie you've ever seen? - Armageddon  http://t.co/qoUXIgdtbZ\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Wholesale #WE Gon Rep That $hit At All Costs- Hazardous #WholeTeam3 #WholesaleEnt https://t.co/JWnXH9Q5ov\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "RT @WIRED: Reddit will now quarantine offensive content http://t.co/zlAGv1U5ZA\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data into training and validation sets."
      ],
      "metadata": {
        "id": "1rI4b6mhGZhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "dN4tXotiHvst"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use trian_test_split to split training data into traning and validation sets.\n",
        "\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
        "    train_df_shuffled[\"text\"].to_numpy(),\n",
        "    train_df_shuffled[\"target\"].to_numpy(),\n",
        "    test_size=0.1,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "ziPtN3maH--_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first 10 samples.\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSZgdNsoIyPy",
        "outputId": "c1864f8e-fc65-4f67-b718-5cfc1905c5fc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object),\n",
              " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting text to numbers.\n",
        "\n",
        "When dealing with text problems one of the first thing we have to do before we build the model is to convert the text to numbers. There are few ways to do this.\n",
        "\n",
        "1. Tokenization: Direct mapping of Tokenization\n",
        "2. Embedding: Create a matrix of feature vector for each token."
      ],
      "metadata": {
        "id": "Wsf_7X7JI1S_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Vectorization (tokenization)"
      ],
      "metadata": {
        "id": "qbnC3PZ8N86D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MztSQLPFODNu",
        "outputId": "95d808f5-6243-487f-95dd-0b499b387827"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "\n",
        "\n",
        "# Use the default TextVectorization parameters.\n",
        "text_vectorizer = TextVectorization(\n",
        "    max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "    standardize=\"lower_and_strip_punctuation\", # how to process text.\n",
        "    split=\"whitespace\", # how to split tokens\n",
        "    ngrams=None, # create groups of n-words?\n",
        "    output_mode=\"int\", # how to map tokens to numbers\n",
        "    output_sequence_length=None, # how long should the output sequence of tokens be?\n",
        "    # pad_to_max_tokens=True\n",
        ")"
      ],
      "metadata": {
        "id": "L_cpnbcoOFJt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the average numbers of token (words) in the traning data.\n",
        "average_number_of_token = round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))\n",
        "average_number_of_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g2UgZ38Qp65",
        "outputId": "aa16264b-2434-4a39-a2a9-d38f56fe0d05"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization variables.\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = average_number_of_token # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "\n",
        "# recreating the intance of text_vectorization.\n",
        "text_vectorizer = TextVectorization(\n",
        "    max_tokens=max_vocab_length,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length\n",
        ")"
      ],
      "metadata": {
        "id": "WINknGACQ976"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer to the traning text.\n",
        "\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "3HRYtlD1RtBx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample sentence and tokenize it.\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgCZtxiNSc0u",
        "outputId": "29020651-223c-4307-f235-3a66916b8dea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it.\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "        \\n\\n Vectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkEZzt7kSlVF",
        "outputId": "6fe83eac-f1b1-4db9-f707-598cde423ffe"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " My Instagram just blew up apparently I was featured on I am jazz tonight. How cool is that love her        \n",
            "\n",
            " Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[  13, 2927,   29,  555,   27, 2193,    8,   23, 5659,   11,    8,\n",
              "         160, 3722,  383,   62]])>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary.\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()  # get all of the unique words.\n",
        "top_5_words = words_in_vocab[:5]  # get the most commmon words.\n",
        "bottom_5_words = words_in_vocab[-5:]  # get the least common words.\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\")\n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvs8a723TGZ1",
        "outputId": "543c8050-422a-4768-cb7d-3d83b0c71bc1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an Embedding using an Embedding layer.\n",
        "\n",
        "To make our embedding, we're going to use Tensorflows embedding layer.\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "The paramters we care most about for our embedding layer:\n",
        "1. 'input_dim' = Size of our input vocab.\n",
        "2. 'output_dim' = Size of the output embedding vector.\n",
        "\n",
        "example, a value of 100 would mean each token gets represented by a vector 100 long.\n",
        "3. 'input_length' = length of the sequences being passed to the embedding layer."
      ],
      "metadata": {
        "id": "OFH4tJwiUBDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(\n",
        "    input_dim = max_vocab_length,\n",
        "    output_dim = 128,     # Neural networks works with numbers that are divible by 8.\n",
        ")\n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meierF1ZXBu1",
        "outputId": "65be8c1f-dbad-454c-fb39-ebc5d20f0e7d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Embedding name=embedding_1, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from the training set.\n",
        "random_sentence = random.choice(train_sentences)\n",
        "\n",
        "print(f\"Original text: \\n {random_sentence}\\\n",
        "        \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
        "sample_embed = embedding(\n",
        "    text_vectorizer([random_sentence])\n",
        ")\n",
        "\n",
        "sample_embed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gmWFBHuXmhX",
        "outputId": "3d49d6c8-538c-489a-dcbd-180018c2ab70"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: \n",
            " @fewmoretweets all lives matter. Just not a fan of burning down buildings and stealing from your neighbors to 'protest'        \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.02070825,  0.00765298,  0.0105149 , ...,  0.04538855,\n",
              "          0.02897546,  0.0303595 ],\n",
              "        [-0.00820995,  0.0235048 ,  0.03008392, ..., -0.02235333,\n",
              "         -0.04455527, -0.01259768],\n",
              "        [ 0.0355008 ,  0.0271093 , -0.02990193, ...,  0.00348337,\n",
              "          0.00912484, -0.01921435],\n",
              "        ...,\n",
              "        [ 0.04809816,  0.01661854,  0.03140613, ...,  0.01093914,\n",
              "          0.04141638,  0.01721371],\n",
              "        [-0.01980324,  0.00225959, -0.04708299, ..., -0.04418474,\n",
              "         -0.02382002, -0.0047521 ],\n",
              "        [ 0.00936316,  0.03075707,  0.0013768 , ..., -0.04521279,\n",
              "         -0.03954964,  0.02100245]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single tokne's embedding.\n",
        "\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVKPjP8lYb1T",
        "outputId": "73f6e40c-6ed7-443d-c4a8-d105d3002b9a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.02070825,  0.00765298,  0.0105149 , -0.00507504,  0.02318213,\n",
              "        -0.04947042, -0.04086571, -0.03938166, -0.01144361, -0.01977422,\n",
              "         0.02117089, -0.03671043, -0.03658701, -0.01515947,  0.01380252,\n",
              "        -0.02297257, -0.02620621,  0.00103694,  0.02324638, -0.00149842,\n",
              "        -0.00116354,  0.00053809,  0.00918115,  0.00909287, -0.0295159 ,\n",
              "         0.00633404, -0.00733791, -0.03546342, -0.03824443, -0.02414528,\n",
              "        -0.01838853,  0.02430635,  0.04893638,  0.02299777, -0.04936258,\n",
              "         0.01442727,  0.04046062, -0.02774061,  0.03003857, -0.02359157,\n",
              "         0.01152213, -0.03856277,  0.00358927,  0.01859475, -0.0242699 ,\n",
              "        -0.01922495,  0.02694965,  0.01821828, -0.03144068,  0.01169636,\n",
              "        -0.04336661,  0.03838648,  0.00892727,  0.03824646, -0.02710755,\n",
              "         0.02134088,  0.01113274, -0.02750068, -0.01745981,  0.03685081,\n",
              "        -0.04983065,  0.0079801 , -0.00308383,  0.0137609 ,  0.00574913,\n",
              "        -0.02878654, -0.04536396, -0.04655987,  0.00820785, -0.03315883,\n",
              "        -0.02947338,  0.01428236, -0.00618944, -0.04463387, -0.02961298,\n",
              "        -0.01875662,  0.04536298, -0.02016985, -0.01104945, -0.0349218 ,\n",
              "         0.02462968,  0.00852511, -0.03340875,  0.00914278, -0.01957983,\n",
              "         0.03572095,  0.0477025 , -0.02182484,  0.03556708,  0.04785741,\n",
              "        -0.00398759, -0.0109658 , -0.00438633, -0.0324036 ,  0.03837797,\n",
              "        -0.0408906 ,  0.01289504,  0.0311983 , -0.01946303,  0.01743681,\n",
              "        -0.00768025,  0.01179129, -0.00612004,  0.02613794, -0.04344289,\n",
              "         0.01408542, -0.03641437, -0.01574381, -0.04465358,  0.02364973,\n",
              "         0.02496724,  0.03364208,  0.04747467, -0.0243204 , -0.03485142,\n",
              "        -0.01049764,  0.02268508, -0.00124103, -0.03717122,  0.01815933,\n",
              "        -0.04749928, -0.04799414, -0.00823377,  0.0206914 ,  0.04662831,\n",
              "         0.04538855,  0.02897546,  0.0303595 ], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " '@')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling a text dataset (running a series of experiments)\n",
        "\n",
        "Now we've got a way to turn our text sequences into numbers, it's time to start building a series of modelling experiments.\n",
        "\n",
        "we'll start with a baseline and move on from there.\n",
        "\n",
        "* Model 0: Build a Naive Bayes (baseline): https://scikit-learn.org/stable/modules/naive_bayes.html\n",
        "\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "\n",
        "* Model 2: LSTM model (RNN)\n",
        "\n",
        "* Model 3: GRU model (RNN)\n",
        "\n",
        "* Model 4: Bidirectional_LSTM model (RNN)\n",
        "\n",
        "* Model 5: 1D Convolutional Neural Network(CNN)\n",
        "\n",
        "* Model 6: TensorFlow Hub Pretrained Feature extractor (using transfer learning for NLP)\n",
        "\n",
        "* Model 7: Same as model 6 with 10% of traning data\n",
        "\n",
        "\n",
        "Wei'll use the standard stpes in modelling.\n",
        "\n",
        "* Create a model.\n",
        "* Build a model\n",
        "* Fit the model\n",
        "* Evaluate our model.\n"
      ],
      "metadata": {
        "id": "Y3ajehSEZcC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XuuJ4QgNc8Fw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMPl9ASF0foZjkzEE6KpA3x",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}